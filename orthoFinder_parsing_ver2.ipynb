{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# orthoFinder parser\n",
    "# generate the orphan gene from different level\n",
    "\n",
    "# set up file path\n",
    "species_file_name_table = 'file_list.csv'\n",
    "orthogroup_path = 'Orthogroups.tsv'\n",
    "peptide_file_dir = 'fasta_files'\n",
    "# set up focal groups in list\n",
    "focal_list = [\n",
    "\"PdeltoidesWV94_445_v2.1.protein_primaryTranscriptOnly.fa\",\n",
    "\"PtremulaxPopulusalbaaltv2.1.primaryTrs.pep.fa\",\n",
    "\"PtremulaxPopulusalbav2.1p.primaryTrs.pep.fa\",\n",
    "\"Ptrichocarpa_444_v3.1.protein.fa\",\n",
    "\"PtrichocarpaStettler14_532_v1.1.protein.fa\",\n",
    "\"Ptrichocarpav4.1g.primaryTrs.pep.fa\"\n",
    "]\n",
    "non_focal_sp = 'Acomosus_321_v3.protein.fa'\n",
    "\n",
    "# import packages and read in files\n",
    "import json\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from Bio import SearchIO\n",
    "from Bio import SeqIO\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd \n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "\n",
    "# read files\n",
    "orthogroup = pd.read_csv(orthogroup_path, delimiter='\\t')\n",
    "species_csv = pd.read_csv(species_file_name_table)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/homebrew/anaconda3/envs/binf36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,63) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read fasta files\n",
    "from multiprocessing import Pool\n",
    "peptide_file_dir = Path.cwd() / Path(peptide_file_dir)\n",
    "\n",
    "print(\"reading fasta files\")\n",
    "def read_fasta(file_path, species):\n",
    "    seq_dict = SeqIO.to_dict(SeqIO.parse(file_path, \"fasta\"))\n",
    "    return seq_dict\n",
    "\n",
    "# pool=Pool(species_csv.shape[0])\n",
    "pool=Pool()\n",
    "seq_dict_list=pool.starmap(read_fasta, [(peptide_file_dir / row['file_name.fa'], row['file_name.fa']) for index, row in species_csv.iterrows()])\n",
    "pool.close()\n",
    "species_pep_dict = {}\n",
    "for sn,seq_dict in enumerate(seq_dict_list):\n",
    "    # print(species_csv.iloc[0].species_id)\n",
    "    key = species_csv.iloc[0].species_id\n",
    "    species_pep_dict[key] = seq_dict\n",
    "species_pep_dict\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# read fasta files\n",
    "peptide_file_dir = Path.cwd() / Path(peptide_file_dir)\n",
    "len_list = []\n",
    "for (file_path, species) in tqdm([(peptide_file_dir / row['file_name.fa'], row['file_name.fa']) for index, row in species_csv.iterrows()]):\n",
    "    len_list.append(read_fasta(file_path, species))\n",
    "    \n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 65/65 [01:43<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# read fasta files\n",
    "peptide_file_dir = Path.cwd() / Path(peptide_file_dir)\n",
    "species_pep_dict = {}\n",
    "print(\"reading fasta files\")\n",
    "for index, row in tqdm(species_csv.iterrows()):\n",
    "    species = row['species_id']\n",
    "    pep_seq_file = peptide_file_dir / row['file_name.fa']\n",
    "    seq_dict = SeqIO.to_dict(SeqIO.parse(pep_seq_file, \"fasta\"))\n",
    "    species_pep_dict[species] = seq_dict\n",
    "\n",
    "orthogroup = orthogroup.set_index(\"Orthogroup\")\n",
    "\n",
    "# 108471"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "reading fasta files\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "65it [00:59,  1.10it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "# helper functions\n",
    "def s2l(species_id):\n",
    "    return species_csv.set_index('species_id').loc[species_id]['file_name.fa'][:-3]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "## start parsing\n",
    "orphan_dict = {}\n",
    "subset_dict = {}\n",
    "subset_sn = 0\n",
    "count = 0\n",
    "annotation_table_list = []\n",
    "\n",
    "\n",
    "print(\"start parsing\")\n",
    "for L in tqdm(range(0, len(focal_list)+1)):\n",
    "    for subset in itertools.combinations(focal_list, L):\n",
    "        subset_sn += 1\n",
    "        # skip the empty set\n",
    "        if len(subset) == 0: continue\n",
    "        # trim OG containing non focal species\n",
    "        # prepare a total_filter that is defo not in the focal list\n",
    "        total_filter = orthogroup[s2l(non_focal_sp)].isnull()\n",
    "        for species_id in species_csv.set_index('species_id').index:\n",
    "            # OG have focal sp not null\n",
    "            if species_id in subset:\n",
    "                total_filter = total_filter & orthogroup[s2l(species_id)].notnull()\n",
    "                continue\n",
    "            # every not focal species should be mull\n",
    "            species_filter = orthogroup[s2l(species_id)].isnull()\n",
    "            total_filter = total_filter & species_filter\n",
    "            \n",
    "        current_table = orthogroup[total_filter]\n",
    "        orphan_dict[subset] = current_table.dropna(axis=1)\n",
    "        count += current_table.shape[0]\n",
    "        # print(f\"{list(subset)}: {current_table.shape[0]}\")\n",
    "\n",
    "        gene_list = []\n",
    "        reference_list = []\n",
    "        seq_record_list = []\n",
    "        subset_str = \"\"\n",
    "        # prepare annotation table and output fasta file\n",
    "        for sp in subset:\n",
    "            subset_str = subset_str + sp + \"_\"\n",
    "            for orphan_list in [ og.split(', ') for og in current_table[s2l(sp)] ]:\n",
    "                for orphan in orphan_list:\n",
    "                    gene_list.append(orphan)\n",
    "                    reference_list.append(sp)\n",
    "                    seq_dict = species_pep_dict[sp]\n",
    "                    seq_record_list.append(seq_dict[orphan])\n",
    "        file_name = f\"orphan_{subset_sn}_{len(subset)}_{len(gene_list)}.fasta\"\n",
    "        SeqIO.write(seq_record_list, file_name, \"fasta\")\n",
    "        subset_dict[subset_sn] = subset\n",
    "\n",
    "with open('subset_info.json', 'w') as fp:\n",
    "    json.dump(subset_dict, fp)\n",
    "print(count)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "start parsing\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 7/7 [00:12<00:00,  1.82s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5518\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "%%time\n",
    "\n",
    "gene_list = []\n",
    "\n",
    "reference_list = []\n",
    "level_list = []\n",
    "orthogroup_list = []\n",
    "peptide_length_list = []\n",
    "peptide_list = []\n",
    "isoelectric_point_list = []\n",
    "molecular_weight_list = []\n",
    "aromaticity_list = []\n",
    "instability_index_list = []\n",
    "flexibility_list = []\n",
    "secondary_structure_fraction_list = []\n",
    "\n",
    "bio_embeddings_subcellular_location_list = []\n",
    "bio_embeddings_membrane_soluble_list = []\n",
    "bio_embeddings_disorder_list = []\n",
    "\n",
    "for combination, current_table in tqdm(orphan_dict.items()):\n",
    "    for sp in combination:\n",
    "        for (orthogroup,orphan_list) in [ (orthogroup,orphan_genes.split(', '))  for orthogroup, orphan_genes in current_table[s2l(sp)].iteritems()]:\n",
    "            for orphan in orphan_list:\n",
    "                gene_list.append(orphan)\n",
    "                reference_list.append(sp)\n",
    "                level_list.append(combination)\n",
    "                orthogroup_list.append(orthogroup)\n",
    "                # get peptide sequence\n",
    "                pep_seq = species_pep_dict[sp][orphan]\n",
    "                analysed_seq = ProteinAnalysis(str(pep_seq.seq).strip('*'))\n",
    "                peptide_length_list.append(len(str(pep_seq.seq).strip('*')))\n",
    "                peptide_list.append(pep_seq.seq)\n",
    "                isoelectric_point_list.append(analysed_seq.isoelectric_point())\n",
    "                molecular_weight_list.append(analysed_seq.molecular_weight())\n",
    "                aromaticity_list.append(analysed_seq.aromaticity())\n",
    "                instability_index_list.append(analysed_seq.instability_index())\n",
    "                flexibility_list.append(analysed_seq.flexibility())\n",
    "                secondary_structure_fraction_list.append(analysed_seq.secondary_structure_fraction())\n",
    "                # TODO: add bio_embeddings\n",
    "                # bio_embeddings_subcellular_location_list.append(bio_embeddings_dict[sp][bio_embeddings_dict[species_4]['original_id'] == gene_id]['subcellular_location'].values)\n",
    "                # bio_embeddings_membrane_soluble_list.append(bio_embeddings_dict[sp][bio_embeddings_dict[species_4]['original_id'] == gene_id]['membrane_or_soluble'].values)\n",
    "\n",
    "\n",
    "\n",
    "big_table = pd.DataFrame.from_dict({\n",
    "    \"gene_id\":gene_list,\n",
    "    \"reference\": reference_list,\n",
    "    \"orphan_level\": level_list,\n",
    "    \"orthogroup\": orthogroup_list,\n",
    "    \"peptide_length\": peptide_length_list,\n",
    "    \"peptide_sequence\": peptide_list,\n",
    "    \"isoelectric_point\": isoelectric_point_list,\n",
    "    \"molecular_weight\": molecular_weight_list,\n",
    "    # \"CCTOP\": cctop_list,\n",
    "    \"aromaticity\":aromaticity_list,\n",
    "    \"instability_index\":instability_index_list,\n",
    "    \"flexibility\":flexibility_list,\n",
    "    \"secondary_structure_fraction([Helix, Turn, Sheet])\":secondary_structure_fraction_list,\n",
    "    # \"bio_embeddings_subcellular_location\": bio_embeddings_subcellular_location_list,\n",
    "    # \"bio_embeddings_membrane_soluble\": bio_embeddings_membrane_soluble_list\n",
    "})\n",
    "big_table.to_csv(\"orphan_info_WIP0717.csv\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 63/63 [00:11<00:00,  5.61it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 13.2 s, sys: 126 ms, total: 13.3 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# species_pep_dict['717m'].keys()\n",
    "examine_list = []\n",
    "for sn, gene in enumerate(gene_list):\n",
    "    \n",
    "    sp = reference_list[sn]\n",
    "    seq_dict = species_pep_dict[sp]\n",
    "\n",
    "    # print(seq_dict[gene])\n",
    "    examine_list.append(seq_dict[gene])\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Bio import SeqIO\n",
    "SeqIO.write(examine_list[0:4000], \"orphans_for_blast_1.fasta\", \"fasta\")\n",
    "SeqIO.write(examine_list[4000:], \"orphans_for_blast_2.fasta\", \"fasta\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3305"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af2f17ac45dd6289728e7cd82682c235565ab65b833fdfc762b0327d912ca907"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('binf36': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}